{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jvfCEb7577JdCP5CwTUDw-vB6fgpedUK","timestamp":1676919880521}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["CE080_Vedant_Parikh\n","\n","Machine Learning\n","\n","Lab : 04"],"metadata":{"id":"kb2RF_ORgS7V"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ab_1rRTrIeo","executionInfo":{"status":"ok","timestamp":1677159989210,"user_tz":-330,"elapsed":1662,"user":{"displayName":"CE080_Vedant_Parikh","userId":"04185109320538044022"}},"outputId":"7ce8b14a-053a-4d76-cb35-7707107c5ece"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-2b9f2d86b0ac>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  weights=torch.tensor(weights,requires_grad=True)\n","<ipython-input-4-2b9f2d86b0ac>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  bias=torch.tensor(bias,requires_grad=True)\n"]},{"output_type":"stream","name":"stdout","text":["finalLoss :  0.5140101946832146\n","weights :  tensor([[-0.4154],\n","        [ 0.8482],\n","        [ 0.6743]], grad_fn=<SubBackward0>)\n","bias :  tensor([[1.9665],\n","        [1.9777],\n","        [2.0110],\n","        [2.0035],\n","        [2.0254]], grad_fn=<SubBackward0>)\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","from torchvision.models import resnet18 as model\n","inputs = np.array(\n","    [[73, 67, 43],\n","    [91, 88, 64],\n","    [87, 134, 58],\n","    [102, 43, 37],\n","    [69, 96, 70]], \n","  dtype='float32')\n","targets = np.array([[56.],[81.],[119.],[22.],[103.]])\n","w=[[1.],[1.],[1.]]\n","b=[[2.],[2.],[2.],[2.],[2.]]\n","learningRate=0.0001\n","iterations=1000\n","m=len(inputs)*1.0\n","weights=torch.tensor(w, requires_grad=True)\n","bias=torch.tensor(b, requires_grad=True)\n","finalLoss=0.0\n","for _ in range(iterations):\n","  weights=torch.tensor(weights,requires_grad=True)\n","  bias=torch.tensor(bias,requires_grad=True)\n","  inputs1=torch.tensor(inputs,requires_grad=False)\n","  y1=torch.tensor(targets)\n","  hypo=torch.matmul(inputs1,weights)+bias\n","  loss=((hypo-y1)**2)\n","  myloss=0.0\n","  for row in loss:\n","    myloss+=row[0]\n","  myloss/=2*m\n","  myloss.backward()\n","  weights=weights-((weights.grad)*learningRate)\n","  bias=bias-((bias.grad)*learningRate)\n","  finalLoss=myloss.item()\n","print(\"finalLoss : \",finalLoss)\n","print(\"weights : \",weights)\n","print(\"bias : \",bias)"]}]}